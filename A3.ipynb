{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "import tweepy\nimport json\nimport re\n\nclass MyStreamListener(tweepy.StreamListener):\n    \n    def __init__(self, api=None):\n        super(MyStreamListener, self).__init__()\n        self.num_tweets = 20\n        self.count = 1\n        self.all_tweets = \"\"\n        self.all_tweets_list = []\n    \n    def on_status(self, status):\n        print(status.text)\n        \n    def on_data(self, data):\n        tweet = json.loads(data)\n        if not tweet['retweeted'] and 'RT @' not in tweet['text']:  # remove duplicate tweets\n            if self.count == (self.num_tweets+1):\n                with open('data.json', 'w') as outfile:\n                    json.dump(self.all_tweets_list, outfile)\n                return False\n            t = dict()\n            t['id'] = self.count\n            # remove all emoticons and any other special symbols.\n            emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  \n                           u\"\\U0001F300-\\U0001F5FF\"  \n                           u\"\\U0001F680-\\U0001F6FF\"\n                           u\"\\U0001F1E0-\\U0001F1FF\"\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n            tweet['text'] = emoji_pattern.sub(r'', tweet['text'])\n            t['text'] = tweet['text']\n            self.count += 1\n            self.all_tweets += (json.dumps(t)+\"\\n\")\n            self.all_tweets_list.append(t)  # save \n        return True\n    \n    def on_error(self, status_code):\n        if status_code == 420:\n            return False\n        \n    def get_all_tweets(self):\n        return self.all_tweets\n        \nACCESS_TOKEN = '1040311982015037440-1TSqPfFZmXn1fUS1qplchjVbWBMANn'\nACCESS_SECRET = 'K0efO3na1D9Mw1Du7rkROzgOW8zDTLTG6AcVTuLqMzjQq'\nCONSUMER_KEY = 'j4kLoamWfoPbw72VLoQwjmzeF'\nCONSUMER_SECRET = 'UwEGlKxK2xX4I59FXhwUmc1A4wPoW2ZceTY1ZI2iTdEGDOaOjY'\n\nauth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\nauth.secure = True\nauth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\napi = tweepy.API(auth)\n\nmyStreamListener = MyStreamListener()\nmyStream = tweepy.Stream(auth = api.auth, listener=MyStreamListener())\nmyStream.filter(track=['lol'])\n"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting tweepy\n  Downloading https://files.pythonhosted.org/packages/05/f1/2e8c7b202dd04117a378ac0c55cc7dafa80280ebd7f692f1fa8f27fd6288/tweepy-3.6.0-py2.py3-none-any.whl\nCollecting requests>=2.11.1 (from tweepy)\n  Downloading https://files.pythonhosted.org/packages/f1/ca/10332a30cb25b627192b4ea272c351bce3ca1091e541245cccbace6051d8/requests-2.20.0-py2.py3-none-any.whl (60kB)\n\u001b[K    100% |################################| 61kB 1.7MB/s eta 0:00:01\n\u001b[?25hCollecting requests-oauthlib>=0.7.0 (from tweepy)\n  Downloading https://files.pythonhosted.org/packages/94/e7/c250d122992e1561690d9c0f7856dadb79d61fd4bdd0e598087dce607f6c/requests_oauthlib-1.0.0-py2.py3-none-any.whl\nCollecting six>=1.10.0 (from tweepy)\n  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\nCollecting PySocks>=1.5.7 (from tweepy)\n  Downloading https://files.pythonhosted.org/packages/53/12/6bf1d764f128636cef7408e8156b7235b150ea31650d0260969215bb8e7d/PySocks-1.6.8.tar.gz (283kB)\n\u001b[K    100% |################################| 286kB 2.0MB/s eta 0:00:01\n\u001b[?25hCollecting urllib3<1.25,>=1.21.1 (from requests>=2.11.1->tweepy)\n  Downloading https://files.pythonhosted.org/packages/8c/4b/5cbc4cb46095f369117dcb751821e1bef9dd86a07c968d8757e9204c324c/urllib3-1.24-py2.py3-none-any.whl (117kB)\n\u001b[K    100% |################################| 122kB 3.1MB/s eta 0:00:01\n\u001b[?25hCollecting certifi>=2017.4.17 (from requests>=2.11.1->tweepy)\n  Downloading https://files.pythonhosted.org/packages/56/9d/1d02dd80bc4cd955f98980f28c5ee2200e1209292d5f9e9cc8d030d18655/certifi-2018.10.15-py2.py3-none-any.whl (146kB)\n\u001b[K    100% |################################| 153kB 2.9MB/s eta 0:00:01\n\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests>=2.11.1->tweepy)\n  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n\u001b[K    100% |################################| 143kB 3.0MB/s eta 0:00:01\n\u001b[?25hCollecting idna<2.8,>=2.5 (from requests>=2.11.1->tweepy)\n  Downloading https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl (58kB)\n\u001b[K    100% |################################| 61kB 1.7MB/s eta 0:00:01\n\u001b[?25hCollecting oauthlib>=0.6.2 (from requests-oauthlib>=0.7.0->tweepy)\n  Downloading https://files.pythonhosted.org/packages/e6/d1/ddd9cfea3e736399b97ded5c2dd62d1322adef4a72d816f1ed1049d6a179/oauthlib-2.1.0-py2.py3-none-any.whl (121kB)\n\u001b[K    100% |################################| 122kB 2.4MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: PySocks\n  Running setup.py bdist_wheel for PySocks ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/22/5c/b5/12e0dfdfa85bea67b23628b6425fae715c687e947a45ee3df9\nSuccessfully built PySocks\nInstalling collected packages: urllib3, certifi, chardet, idna, requests, oauthlib, requests-oauthlib, six, PySocks, tweepy\nSuccessfully installed PySocks-1.6.8 certifi-2018.10.15 chardet-3.0.4 idna-2.7 oauthlib-2.1.0 requests-2.20.0 requests-oauthlib-1.0.0 six-1.11.0 tweepy-3.6.0 urllib3-1.24\n"
                }
            ], 
            "source": "!pip install tweepy"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+---+--------------------+\n| id|                text|\n+---+--------------------+\n|  1|I\u2019m getting me a ...|\n|  2|       Chill out lol|\n|  3|nunca achei que e...|\n|  4|Narrator:  They d...|\n|  5|@ayeetrey_ lol yo...|\n|  6|      Trae Young lol|\n|  7|I dont know about...|\n|  8|Talk to em ! Pipe...|\n|  9|lol i guess not w...|\n| 10|@Lift_andLove Lol...|\n| 11|anyways atiku lat...|\n| 12|So Spotify follow...|\n| 13|@JChanDaLand Lol ...|\n| 14|a vontade que eu ...|\n| 15|@Lulubookseller @...|\n| 16|Lol and there you...|\n| 17|Now this is a lit...|\n| 18|Ya lo v\u00ed todo. Pa...|\n| 19|@alex_robinson04 ...|\n| 20|Hell yeah @Succes...|\n+---+--------------------+\n\n"
                }
            ], 
            "source": "import pyspark \nfrom pyspark.sql import SQLContext\n\nspark = SparkSession.builder.config(conf=SparkConf()).getOrCreate()\nsc = SparkContext.getOrCreate()\nsqlc = SQLContext(sc)\ndf = sqlc.read.json(\"data.json\",multiLine=True)\ndf.show()"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-----+--------------------+\n|label|                text|\n+-----+--------------------+\n|    4|Reading my kindle...|\n|    4|Ok, first assesme...|\n|    4|@kenburbary You'l...|\n|    4|@mikefish  Fair e...|\n|    4|@richardebaker no...|\n|    0|Fuck this economy...|\n|    4|Jquery is my new ...|\n|    4|       Loves twitter|\n|    4|how can you not l...|\n|    2|Check this video ...|\n|    0|@Karoli I firmly ...|\n|    4|House Corresponde...|\n|    4|Watchin Espn..Jus...|\n|    0|dear nike, stop w...|\n|    4|#lebron best athl...|\n|    0|I was talking to ...|\n|    4|i love lebron. ht...|\n|    0|@ludajuice Lebron...|\n|    4|@Pmillzz lebron I...|\n|    4|@sketchbug Lebron...|\n+-----+--------------------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "F1: 0.674556\n"
                }
            ], 
            "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql import types\n\ndf_data_2 = df_data_2.withColumn(\"label\", df_data_2.label.cast(\"Int\"))\n\n(train, test) = df_data_2.randomSplit([0.9, 0.1], seed = 1000)\n\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\nlr = LogisticRegression(maxIter=20,regParam=0.001)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n\n# Fit the pipeline to training documents.\nmodel= pipeline.fit(train)\n\n# Make predictions on test documents and print columns of interest.\npredictions = model.transform(test)\n#predictions.show()\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nprint(\"F1: %g\" % (evaluator.evaluate(predictions)))\n\n#save the model, overwrite if the model already exist\n#model.save(\"logreg.model\")\nmodel.write().overwrite().save(\"logreg.model\")\n"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n| id|                text|               words|            features|       rawPrediction|         probability|prediction|\n+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n|  1|I\u2019m getting me a ...|[i\u2019m, getting, me...|(262144,[9639,223...|[1.66040780300058...|[0.10698119672902...|       4.0|\n|  2|       Chill out lol|   [chill, out, lol]|(262144,[21007,31...|[2.11125231084676...|[0.23909885459871...|       4.0|\n|  3|nunca achei que e...|[nunca, achei, qu...|(262144,[3934,507...|[1.99762596666603...|[0.21116663227740...|       2.0|\n|  4|Narrator:  They d...|[narrator:, , the...|(262144,[60108,61...|[3.72277660856545...|[0.74898544122468...|       0.0|\n|  5|@ayeetrey_ lol yo...|[@ayeetrey_, lol,...|(262144,[1536,951...|[8.07048891535554...|[0.99941090139007...|       0.0|\n|  6|      Trae Young lol|  [trae, young, lol]|(262144,[31950,13...|[1.87547934277638...|[0.17945818873223...|       4.0|\n|  7|I dont know about...|[i, dont, know, a...|(262144,[24417,24...|[4.86923955830071...|[0.80587510962049...|       0.0|\n|  8|Talk to em ! Pipe...|[talk, to, em, !,...|(262144,[25217,28...|[3.01350508725911...|[0.54091980848569...|       0.0|\n|  9|lol i guess not w...|[lol, i, guess, n...|(262144,[4649,517...|[4.02238704800620...|[0.45732495718337...|       4.0|\n| 10|@Lift_andLove Lol...|[@lift_andlove, l...|(262144,[4200,158...|[2.18065563087436...|[0.23851152825635...|       4.0|\n| 11|anyways atiku lat...|[anyways, atiku, ...|(262144,[3917,196...|[4.02321780873369...|[0.83529765252830...|       0.0|\n| 12|So Spotify follow...|[so, spotify, fol...|(262144,[7973,158...|[2.14946568233597...|[0.11182416863887...|       4.0|\n| 13|@JChanDaLand Lol ...|[@jchandaland, lo...|(262144,[11104,19...|[1.95766363183090...|[0.19370957356004...|       2.0|\n| 14|a vontade que eu ...|[a, vontade, que,...|(262144,[23442,31...|[1.90753850435181...|[0.17848598285916...|       4.0|\n| 15|@Lulubookseller @...|[@lulubookseller,...|(262144,[22218,24...|[1.32990927660013...|[0.06771218847237...|       4.0|\n| 16|Lol and there you...|[lol, and, there,...|(262144,[31950,91...|[1.76178049102002...|[0.12999731541617...|       4.0|\n| 17|Now this is a lit...|[now, this, is, a...|(262144,[9639,158...|[3.28685157892928...|[0.54786061221587...|       0.0|\n| 18|Ya lo v\u00ed todo. Pa...|[ya, lo, v\u00ed, todo...|(262144,[29004,31...|[3.26697319576183...|[0.63229986471415...|       0.0|\n| 19|@alex_robinson04 ...|[@alex_robinson04...|(262144,[1379,963...|[3.34759797545745...|[0.64102414862356...|       0.0|\n| 20|Hell yeah @Succes...|[hell, yeah, @suc...|(262144,[17812,31...|[3.10971685844104...|[0.57396296627828...|       0.0|\n+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n\n"
                }
            ], 
            "source": "from pyspark.ml import PipelineModel\npipelineModel = PipelineModel.load(\"logreg.model\")\nprediction = pipelineModel.transform(df)\nprediction.show()"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+---+--------------------+----------+\n| id|                text|prediction|\n+---+--------------------+----------+\n|  1|I\u2019m getting me a ...|       4.0|\n|  2|       Chill out lol|       4.0|\n|  6|      Trae Young lol|       4.0|\n|  9|lol i guess not w...|       4.0|\n| 10|@Lift_andLove Lol...|       4.0|\n| 12|So Spotify follow...|       4.0|\n| 14|a vontade que eu ...|       4.0|\n| 15|@Lulubookseller @...|       4.0|\n| 16|Lol and there you...|       4.0|\n+---+--------------------+----------+\n\n+---+--------------------+----------+\n| id|                text|prediction|\n+---+--------------------+----------+\n|  3|nunca achei que e...|       2.0|\n| 13|@JChanDaLand Lol ...|       2.0|\n+---+--------------------+----------+\n\n+---+--------------------+----------+\n| id|                text|prediction|\n+---+--------------------+----------+\n|  4|Narrator:  They d...|       0.0|\n|  5|@ayeetrey_ lol yo...|       0.0|\n|  7|I dont know about...|       0.0|\n|  8|Talk to em ! Pipe...|       0.0|\n| 11|anyways atiku lat...|       0.0|\n| 17|Now this is a lit...|       0.0|\n| 18|Ya lo v\u00ed todo. Pa...|       0.0|\n| 19|@alex_robinson04 ...|       0.0|\n| 20|Hell yeah @Succes...|       0.0|\n+---+--------------------+----------+\n\n"
                }
            ], 
            "source": "#show positive tweets\nprediction.filter(prediction['prediction'] == 4).select(\"id\",\"text\",\"prediction\").show(10)\n\n#show natural tweets\nprediction.filter(prediction['prediction'] == 2).select(\"id\",\"text\",\"prediction\").show(10)\n\n#show negative tweets\nprediction.filter(prediction['prediction'] == 0).select(\"id\",\"text\",\"prediction\",).show(10)"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark", 
            "name": "python3", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}