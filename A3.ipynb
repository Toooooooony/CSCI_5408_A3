{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 95, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "import tweepy\nimport json\nimport re\n\nclass MyStreamListener(tweepy.StreamListener):\n    \n    def __init__(self, api=None):\n        super(MyStreamListener, self).__init__()\n        self.num_tweets = 2018\n        self.count = 1\n        self.all_tweets = \"\"\n        self.all_tweets_list = []\n    \n    def on_status(self, status):\n        print(status.text)\n        \n    def on_data(self, data):\n        tweet = json.loads(data)\n        if not tweet['retweeted'] and 'RT @' not in tweet['text']:\n            if self.count == (self.num_tweets+1):\n                #print(self.all_tweets)\n                #print(self.all_tweets_list)\n                with open('data.json', 'w') as outfile:\n                    json.dump(self.all_tweets_list, outfile)\n                return False\n            t = dict()\n            t['id'] = self.count\n            emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n            tweet['text'] = emoji_pattern.sub(r'', tweet['text'])\n            t['text'] = tweet['text']\n            self.count += 1\n            self.all_tweets += (json.dumps(t)+\"\\n\")\n            self.all_tweets_list.append(t)\n            #print(t)\n        return True\n    \n    def on_error(self, status_code):\n        if status_code == 420:\n            return False\n        \n    def get_all_tweets(self):\n        return self.all_tweets\n        \nACCESS_TOKEN = '1040311982015037440-1TSqPfFZmXn1fUS1qplchjVbWBMANn'\nACCESS_SECRET = 'K0efO3na1D9Mw1Du7rkROzgOW8zDTLTG6AcVTuLqMzjQq'\nCONSUMER_KEY = 'j4kLoamWfoPbw72VLoQwjmzeF'\nCONSUMER_SECRET = 'UwEGlKxK2xX4I59FXhwUmc1A4wPoW2ZceTY1ZI2iTdEGDOaOjY'\n\nauth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\nauth.secure = True\nauth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\napi = tweepy.API(auth)\n\nmyStreamListener = MyStreamListener()\nmyStream = tweepy.Stream(auth = api.auth, listener=MyStreamListener())\nmyStream.filter(track=['lol'])\n"
        }, 
        {
            "execution_count": 96, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+---+--------------------+\n| id|                text|\n+---+--------------------+\n|  1|@cenkuygur @polit...|\n|  2|@SplashIQ A: i do...|\n|  3|     I\u2019m excited lol|\n|  4|@CurlsAndSports S...|\n|  5|//Sorry but this ...|\n|  6|       Lol irritated|\n|  7|@Sabree____ I don...|\n|  8|Lol nigga dropped...|\n|  9|@ConnectionEnded ...|\n| 10|            Stop lol|\n| 11|This will have me...|\n| 12|GOD DAMMIT! It to...|\n| 13|@MandJTV_Michael ...|\n| 14|AlL oF tHe oLd Ra...|\n| 15|Me and the Dean o...|\n| 16|Lol there was a p...|\n| 17|@steph62490 eh ou...|\n| 18|Click ..click... ...|\n| 19|@Soddem_666 Looks...|\n| 20|I worked out too ...|\n+---+--------------------+\n\n"
                }
            ], 
            "source": "import pyspark \nfrom pyspark.sql import SQLContext\n\nspark = SparkSession.builder.config(conf=SparkConf()).getOrCreate()\nsc = SparkContext.getOrCreate()\nsqlc = SQLContext(sc)\ndf = sqlc.read.json(\"data.json\",multiLine=True)\ndf.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 75, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "F1: 0.674556\n"
                }
            ], 
            "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql import types\n\ndf_data_2 = df_data_2.withColumn(\"label\", df_data_2.label.cast(\"Int\"))\n#train = df_data_2\n(train, test) = df_data_2.randomSplit([0.9, 0.1], seed = 1000)\n\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\nlr = LogisticRegression(maxIter=20,regParam=0.001)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n\n# Fit the pipeline to training documents.\nmodel= pipeline.fit(train)\n\n# Make predictions on test documents and print columns of interest.\npredictions = model.transform(test)\n#predictions.show()\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nprint(\"F1: %g\" % (evaluator.evaluate(predictions)))\n\nmodel.write().overwrite().save(\"logreg.model\")\n"
        }, 
        {
            "execution_count": 97, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n| id|                text|               words|            features|       rawPrediction|         probability|prediction|\n+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n|  1|@cenkuygur @polit...|[@cenkuygur, @pol...|(262144,[15889,27...|[2.13603758058881...|[0.21718246030064...|       4.0|\n|  2|@SplashIQ A: i do...|[@splashiq, a:, i...|(262144,[9639,132...|[4.21818986059459...|[0.74961251262493...|       0.0|\n|  3|     I\u2019m excited lol| [i\u2019m, excited, lol]|(262144,[31950,61...|[1.57457674815598...|[0.08050379155457...|       4.0|\n|  4|@CurlsAndSports S...|[@curlsandsports,...|(262144,[8727,201...|[1.87547934277638...|[0.17945818873223...|       4.0|\n|  5|//Sorry but this ...|[//sorry, but, th...|(262144,[15889,19...|[3.13322736106635...|[0.55614350596356...|       0.0|\n|  6|       Lol irritated|    [lol, irritated]|(262144,[31950,18...|[1.87547934277638...|[0.17945818873223...|       4.0|\n|  7|@Sabree____ I don...|[@sabree____, i, ...|(262144,[24417,31...|[2.39590587191473...|[0.31198091508282...|       4.0|\n|  8|Lol nigga dropped...|[lol, nigga, drop...|(262144,[22323,31...|[2.10001974885280...|[0.23286890806632...|       4.0|\n|  9|@ConnectionEnded ...|[@connectionended...|(262144,[15889,31...|[2.37392299730552...|[0.30038280508055...|       4.0|\n| 10|            Stop lol|         [stop, lol]|(262144,[31950,20...|[2.41010019462933...|[0.32520882029843...|       4.0|\n| 11|This will have me...|[this, will, have...|(262144,[11324,89...|[1.92643385340382...|[0.18715555791356...|       4.0|\n| 12|GOD DAMMIT! It to...|[god, dammit!, it...|(262144,[6744,963...|[2.93186442538246...|[0.48305932095145...|       0.0|\n| 13|@MandJTV_Michael ...|[@mandjtv_michael...|(262144,[31950,37...|[1.93532141429286...|[0.13568219643963...|       4.0|\n| 14|AlL oF tHe oLd Ra...|[all, of, the, ol...|(262144,[4200,963...|[3.71783950262579...|[0.76583406887511...|       0.0|\n| 15|Me and the Dean o...|[me, and, the, de...|(262144,[8449,961...|[3.41672495394734...|[0.53665228268605...|       0.0|\n| 16|Lol there was a p...|[lol, there, was,...|(262144,[16332,24...|[2.02392577718842...|[0.03548962149252...|       4.0|\n| 17|@steph62490 eh ou...|[@steph62490, eh,...|(262144,[18910,28...|[1.53429262471218...|[0.10758349373386...|       2.0|\n| 18|Click ..click... ...|[click, ..click.....|(262144,[155930,2...|[1.98688801933343...|[0.20966349186811...|       2.0|\n| 19|@Soddem_666 Looks...|[@soddem_666, loo...|(262144,[31950,34...|[1.98717715288288...|[0.18419235924362...|       4.0|\n| 20|I worked out too ...|[i, worked, out, ...|(262144,[2437,952...|[4.25958601692562...|[0.64410764021632...|       0.0|\n+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n\n"
                }
            ], 
            "source": "from pyspark.ml import PipelineModel\npipelineModel = PipelineModel.load(\"logreg.model\")\nprediction = pipelineModel.transform(df)\nprediction.show()"
        }, 
        {
            "execution_count": 98, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+---+------------------------------+----------+\n| id|                          text|prediction|\n+---+------------------------------+----------+\n| 19|@Soddem_666 Looks like fara...|       4.0|\n| 16|Lol there was a point when ...|       4.0|\n| 13|@MandJTV_Michael Only do it...|       4.0|\n| 11|This will have me super ner...|       4.0|\n| 10|                      Stop lol|       4.0|\n|  9|@ConnectionEnded @IFleshMer...|       4.0|\n|  8|Lol nigga dropped the mic s...|       4.0|\n|  7|@Sabree____ I don\u2019t be seei...|       4.0|\n|  6|                 Lol irritated|       4.0|\n|  4|@CurlsAndSports Saludos des...|       4.0|\n+---+------------------------------+----------+\nonly showing top 10 rows\n\n+---+------------------------------+----------+\n| id|                          text|prediction|\n+---+------------------------------+----------+\n| 18|        Click ..click... click|       2.0|\n| 17|@steph62490 eh oui pour ca ...|       2.0|\n+---+------------------------------+----------+\n\n+---+------------------------------+----------+\n| id|                          text|prediction|\n+---+------------------------------+----------+\n| 20|I worked out too hard today...|       0.0|\n| 15|Me and the Dean of my depar...|       0.0|\n| 14|AlL oF tHe oLd RaCist WiLl ...|       0.0|\n| 12|GOD DAMMIT! It took us so m...|       0.0|\n|  5|//Sorry but this is the big...|       0.0|\n|  2|@SplashIQ A: i don't watch ...|       0.0|\n+---+------------------------------+----------+\n\n"
                }
            ], 
            "source": "prediction.filter(prediction['prediction'] == 4) \\\n    .select(\"id\",\"text\",\"prediction\") \\\n    .orderBy(\"id\", ascending=False) \\\n    .show(n = 10, truncate = 30)\n\nprediction.filter(prediction['prediction'] == 2) \\\n    .select(\"id\",\"text\",\"prediction\") \\\n    .orderBy(\"id\", ascending=False) \\\n    .show(n = 10, truncate = 30)\n\nprediction.filter(prediction['prediction'] == 0) \\\n    .select(\"id\",\"text\",\"prediction\",) \\\n    .orderBy(\"id\", ascending=False) \\\n    .show(n = 10, truncate = 30)"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark", 
            "name": "python3", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}